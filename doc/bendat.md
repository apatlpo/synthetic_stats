# Bendat and Piersol: notes

Page count based on 3rd edition

- section 1.4.3 (p23): bias vs random error
- section 3.1.1 (p50): standard distributions with probability density functions
- section 3.1.2 (p53): expected values of a function $g(x)$ where $x$ is a random distribution with density distribution $p(x)$ - $E[p(x)] = \int g(x) p(x) dx$
- section 3.2.2 (p61): distribution of the sum of two variables - $p(z)=\int p_1(x) p_2(z-x) dx$
- section 3.3.1 (p65): central limit theorem - "let $x_1(k), ..., x_N(k)$ be $N$ mutually independent random variables whose individual distributions are not specified and may be different. Let $\mu_i$ and $\sigma_i^2$ be the mean value and variance of each random variable $x_i(k)$. Consider the sum random variable $x_(k) = \sum_{i=1,N} a_i x_i(k)$ where $a_i$ are arbitrary fixed constants. The central limit theorem states that under fairly common conditoins the sum random variable $x(k)$ will be normally distributed as $N\rightarrow\infty$ " with mean and variance straightforwardly related to $a_i$ and $x_i$ mean and variances.
- section 3.4.1 (p73): distribution of envelope and phase for narrow bandwidth data - Rayleigh distribution
- example 3.7 (p81): distribution of a sine wave with gaussian noise
- section 4.1 (86): sample values and parameter estimation - sample mean, variance, unbiased/efficient estimators
- section 4.2 (p89): important distributions - gaussian, chi-square, t-distribution, F distribution
- section 4.3.3 (p95): distribution of sample mean with unknown variance
- section 4.3.4 (p95): distribution of ratio of two sample variances
- section 4.4 (p96): confidence intervals
- section 4.5 (p99): hypothesis tests - chi-square goodness of fit test, non-parametric trend test
- section 4.6 (p108): correlation and regression procedures
- example 5.3: autocorrelation function of sum of two processes


